<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CPSC_440 - Lecture 2026-01-07</title>
    <link rel="stylesheet" href="../../styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css">
</head>
<body>
    <div class="container">
        <nav class="breadcrumb">
            <a href="../../index.html">Home</a> /
            <a href="../../index.html#cpsc440">CPSC_440</a> /
            <span>2026-01-07</span>
        </nav>

        <header class="lecture-header">
            <h1>Advanced Machine Learning</h1>
            <div class="lecture-meta">
                <span class="date">üìÖ 2026-01-07</span>
                <span class="instructor">üë§ Danica Sutherland</span>
            </div>
        </header>

        <div class="lecture-content">
            <section class="raw-notes">
                <h2>Quick Notes</h2>
                <div class="notes-box">
                    <p><strong>Admin Updates:</strong></p>
                    <ul>
                        <li>Sign up for Piazza from cs.ubc.ca/~dsuth/440 - lecture recordings now linked</li>
                        <li>CBTF quiz booking coming soon (may push quiz schedule back a week)</li>
                        <li>Assignment 1 out tonight/tomorrow morning</li>
                        <li>Office hours starting next week - calendar on Piazza</li>
                    </ul>

                    <p><strong>Last Time Recap:</strong></p>
                    <ul>
                        <li>Density estimation: data ‚Üí probability model</li>
                        <li>Inference: using probability model for tasks (computing probabilities, likelihoods, sampling)</li>
                        <li>Bernoulli distribution: p(x|Œ∏) = Œ∏À£(1-Œ∏)¬π‚ÅªÀ£</li>
                    </ul>

                    <p><strong>Maximum Likelihood Estimation (MLE):</strong></p>
                    <ul>
                        <li>Likelihood function: L(Œ∏) = p(X|Œ∏) = Œ∏‚Åø¬π(1-Œ∏)‚Åø‚Å∞</li>
                        <li>MLE: pick Œ∏ with highest likelihood</li>
                        <li>For Bernoulli: Œ∏ÃÇ = n‚ÇÅ/n (just the sample mean!)</li>
                        <li>Derivation: maximize log-likelihood, set derivative to zero</li>
                        <li>Problem: Can overfit on small datasets</li>
                    </ul>

                    <p><strong>Maximum A Posteriori (MAP) Estimation:</strong></p>
                    <ul>
                        <li>Instead of maximizing p(X|Œ∏), maximize p(Œ∏|X)</li>
                        <li>Using Bayes rule: p(Œ∏|X) ‚àù p(X|Œ∏) ¬∑ p(Œ∏)</li>
                        <li>Requires choosing a prior distribution p(Œ∏)</li>
                        <li>Beta prior: p(Œ∏|Œ±,Œ≤) ‚àù Œ∏·µÖ‚Åª¬π(1-Œ∏)·µù‚Åª¬π</li>
                        <li>Beta-Bernoulli posterior is also Beta: Œ∏|X ~ Beta(Œ±+n‚ÇÅ, Œ≤+n‚ÇÄ)</li>
                        <li>MAP estimate: Œ∏ÃÇ = (n‚ÇÅ+Œ±-1)/(n+Œ±+Œ≤-2)</li>
                        <li>Special cases: Œ±=Œ≤=1 ‚Üí MLE, Œ±=Œ≤=2 ‚Üí Laplace smoothing</li>
                    </ul>

                    <p><strong>Key Concepts:</strong></p>
                    <ul>
                        <li>Proportional-to notation: f(Œ∏) ‚àù g(Œ∏) means f(Œ∏) = Œ∫g(Œ∏) for some Œ∫>0</li>
                        <li>Continuous distributions: use probability density functions (pdfs)</li>
                        <li>Hyperparameters (Œ±, Œ≤): chose via validation/cross-validation</li>
                        <li>As n‚Üí‚àû, MAP converges to MLE</li>
                    </ul>
                </div>
            </section>

            <section class="expanded-notes">
                <h2>Detailed Notes</h2>
                <div id="notes-content">

                    <!-- ===== REVIEW FROM LAST TIME ===== -->
                    <article>
                        <h3>Review: From Density Estimation to Parameter Learning</h3>

                        <p>In the last lecture, we established the foundation: <strong>binary density estimation</strong> using the Bernoulli distribution. Today we tackle the next natural question: <em>how do we actually learn the parameter Œ∏ from data?</em></p>

                        <h4>Quick Refresher: What We Know</h4>

                        <p><strong>Density Estimation:</strong> The process of going from data to a probability model</p>
                        <ul>
                            <li><strong>Input:</strong> Binary data <code>X = [x‚ÅΩ¬π‚Åæ, x‚ÅΩ¬≤‚Åæ, ..., x‚ÅΩ‚Åø‚Åæ]</code> where each <code>x‚ÅΩ‚Å±‚Åæ ‚àà {0, 1}</code></li>
                            <li><strong>Output:</strong> A parameterized model that describes the data's probability distribution</li>
                        </ul>

                        <p><strong>Inference:</strong> Using a probability model to "do things"</p>
                        <ul>
                            <li>Computing probabilities of derived events (e.g., "What's the probability 3+ out of 10 are positive?")</li>
                            <li>Computing likelihoods (how probable is this dataset?)</li>
                            <li>Finding the mode (most likely value)</li>
                            <li>Sampling (generating new data from the distribution)</li>
                        </ul>

                        <p><strong>The Bernoulli Distribution:</strong></p>

                        <blockquote>
                            <p>If <code>X ~ Bern(Œ∏)</code>, then for <code>x ‚àà {0, 1}</code> we have:</p>
                            <p style="text-align: center; font-size: 1.1em;"><code>Pr(X = x | Œ∏) = Œ∏À£(1 - Œ∏)¬π‚ÅªÀ£</code></p>
                        </blockquote>

                        <p>We can write this more explicitly:</p>
                        <ul>
                            <li><code>Pr(X = 1 | Œ∏) = Œ∏</code></li>
                            <li><code>Pr(X = 0 | Œ∏) = 1 - Œ∏</code></li>
                        </ul>

                        <p><strong>Notation reminder:</strong> We might also write <code>p(x | Œ∏)</code> or even just <code>p(x)</code> when the context is clear. Be careful to track what's being abbreviated!</p>

                        <h4>The Learning Problem</h4>

                        <p>Last time we learned how to <em>use</em> a Bernoulli model (inference). Today's question: <mark>How do we <em>train</em> or <em>learn</em> a Bernoulli model from data?</mark></p>

                        <p><strong>The setup:</strong></p>
                        <pre><code class="language-plaintext">Data:  X = [1, 0, 0, 1, 0]

Learning Algorithm: ???

Output: Œ∏ÃÇ = 0.4</code></pre>

                        <p>We need a principled way to estimate Œ∏ from the observed data. Today we'll explore two fundamental approaches:</p>
                        <ol>
                            <li><strong>Maximum Likelihood Estimation (MLE)</strong> ‚Äî Pick the Œ∏ that makes the data most likely</li>
                            <li><strong>Maximum A Posteriori (MAP) Estimation</strong> ‚Äî Pick the Œ∏ that is most probable given the data</li>
                        </ol>

                        <p>These might sound similar, but they're subtly different‚Äîand that difference matters a lot in practice!</p>
                    </article>

                    <!-- ===== LIKELIHOOD FUNCTION ===== -->
                    <article>
                        <h3>The Likelihood Function: Measuring How Well Œ∏ Explains the Data</h3>

                        <h4>What is a Likelihood Function?</h4>

                        <blockquote>
                            <p><strong>Definition:</strong> The likelihood function is a function from parameters Œ∏ to the probability (density) of observing the data under those parameters.</p>
                            <p style="text-align: center; font-size: 1.1em;"><code>L(Œ∏) = p(X | Œ∏)</code></p>
                        </blockquote>

                        <p><strong>Key insight:</strong> Think of the likelihood as asking: "If the parameter was Œ∏, how probable would it be to observe exactly this data X?"</p>

                        <p>For Bernoulli data with n‚ÇÅ ones and n‚ÇÄ zeros:</p>
                        <p style="text-align: center; font-size: 1.1em;"><code>L(Œ∏) = Œ∏‚Åø¬π ¬∑ (1 - Œ∏)‚Åø‚Å∞</code></p>

                        <h4>Example: Visualizing the Likelihood</h4>

                        <p>Let's compute the likelihood for the dataset <code>X = [1, 0, 1]</code> (n‚ÇÅ = 2, n‚ÇÄ = 1), which gives us <code>L(Œ∏) = Œ∏¬≤(1-Œ∏)</code>:</p>

                        <table style="width: 100%; border-collapse: collapse; margin: 1.5rem 0;">
                            <thead>
                                <tr style="background: var(--secondary-bg);">
                                    <th style="padding: 0.75rem; text-align: left; border: 1px solid var(--border-color);">Œ∏ value</th>
                                    <th style="padding: 0.75rem; text-align: left; border: 1px solid var(--border-color);">Calculation</th>
                                    <th style="padding: 0.75rem; text-align: right; border: 1px solid var(--border-color);">L(Œ∏)</th>
                                    <th style="padding: 0.75rem; text-align: left; border: 1px solid var(--border-color);">Interpretation</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">Œ∏ = 0</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">0¬≤ ¬∑ (1-0) = 0 ¬∑ 1</td>
                                    <td style="padding: 0.75rem; text-align: right; border: 1px solid var(--border-color);">0</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">Impossible (we saw 1s!)</td>
                                </tr>
                                <tr>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">Œ∏ = 0.5</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">0.5¬≤ ¬∑ 0.5 = 0.25 ¬∑ 0.5</td>
                                    <td style="padding: 0.75rem; text-align: right; border: 1px solid var(--border-color);">0.125</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">Moderately likely</td>
                                </tr>
                                <tr style="background: var(--secondary-bg);">
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);"><strong>Œ∏ = 2/3</strong></td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">(2/3)¬≤ ¬∑ (1/3)</td>
                                    <td style="padding: 0.75rem; text-align: right; border: 1px solid var(--border-color);"><strong>‚âà 0.148</strong></td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);"><strong>Maximum!</strong></td>
                                </tr>
                                <tr>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">Œ∏ = 0.75</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">0.75¬≤ ¬∑ 0.25 = 0.5625 ¬∑ 0.25</td>
                                    <td style="padding: 0.75rem; text-align: right; border: 1px solid var(--border-color);">‚âà 0.14</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">Pretty likely, but not maximum</td>
                                </tr>
                                <tr>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">Œ∏ = 1</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">1¬≤ ¬∑ (1-1) = 1 ¬∑ 0</td>
                                    <td style="padding: 0.75rem; text-align: right; border: 1px solid var(--border-color);">0</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">Impossible (we saw a 0!)</td>
                                </tr>
                            </tbody>
                        </table>

                        <p><strong>Key observations:</strong></p>
                        <ul>
                            <li>The dataset <code>[1, 0, 1]</code> is <em>more likely</em> for Œ∏ = 0.75 than Œ∏ = 0.5</li>
                            <li>The dataset is <em>impossible</em> for Œ∏ = 0 or Œ∏ = 1 (since we have both 0s and 1s)</li>
                            <li>The maximum likelihood occurs at Œ∏ = 2/3 ‚âà 0.667</li>
                        </ul>

                        <h4>Important Distinction: Likelihood is NOT a Probability Distribution</h4>

                        <p>‚ö†Ô∏è <strong>Common misconception:</strong> The likelihood function L(Œ∏) is <strong>not</strong> a probability distribution over Œ∏!</p>

                        <p><strong>Why not?</strong></p>
                        <ul>
                            <li>We don't have <code>‚à´ L(Œ∏) dŒ∏ = 1</code></li>
                            <li>L(Œ∏) is a function of the parameter, not the data</li>
                            <li>It measures "how likely the data is for different Œ∏ values," not "how probable different Œ∏ values are"</li>
                        </ul>

                        <p><strong>What we do have:</strong></p>
                        <ul>
                            <li><code>‚à´ p(X | Œ∏) dX = 1</code> ‚Äî for a fixed Œ∏, probabilities over data sum/integrate to 1</li>
                            <li>But when we have one fixed dataset X, this isn't relevant</li>
                        </ul>

                        <p>This distinction will become crucial when we introduce priors and Bayesian inference!</p>
                    </article>

                    <!-- ===== MLE ===== -->
                    <article>
                        <h3>Maximum Likelihood Estimation (MLE): Pick the Most Explanatory Œ∏</h3>

                        <h4>The MLE Principle</h4>

                        <blockquote>
                            <p><strong>Maximum Likelihood Estimation (MLE):</strong> Choose the parameter Œ∏ that maximizes the likelihood of observing the data.</p>
                            <p style="text-align: center; font-size: 1.1em;"><code>Œ∏ÃÇ ‚àà arg max<sub>Œ∏</sub> L(Œ∏) = arg max<sub>Œ∏</sub> p(X | Œ∏)</code></p>
                        </blockquote>

                        <p><strong>In words:</strong> "Find the parameters Œ∏ where the data X would have been most likely to be observed."</p>

                        <p><strong>The arg max notation:</strong></p>
                        <ul>
                            <li><code>arg max<sub>x</sub> f(x)</code> means "the set of x values that maximize f"</li>
                            <li>There might be more than one! (That's why we write <code>‚àà</code> instead of <code>=</code>)</li>
                            <li>Example: <code>arg max<sub>x</sub> x¬≤</code> doesn't exist (no maximum), but <code>arg max<sub>x‚àà[-1,1]</sub> x¬≤ = {-1, 1}</code></li>
                        </ul>

                        <h4>MLE for Bernoulli Distribution</h4>

                        <p>For Bernoulli data, the MLE has a beautiful, intuitive form:</p>

                        <blockquote>
                            <p style="text-align: center; font-size: 1.2em;"><code>Œ∏ÃÇ<sub>MLE</sub> = n‚ÇÅ/n = n‚ÇÅ/(n‚ÇÅ + n‚ÇÄ)</code></p>
                        </blockquote>

                        <p><strong>In other words:</strong> The MLE is just the <em>sample proportion</em> of 1s!</p>

                        <p><strong>Intuitive example:</strong> "If you flip a coin 50 times and get 23 heads, guess that Pr(heads) = 23/50 = 0.46"</p>

                        <p><strong>Python implementation:</strong></p>
                        <pre><code class="language-python">theta_mle = np.mean(X)  # Takes O(n) time</code></pre>

                        <p>That's it! For Bernoulli, MLE is trivially simple to compute.</p>

                        <h4>Deriving the MLE (The Hard Way)</h4>

                        <p>While the result is simple, let's derive it rigorously. This derivation technique generalizes to much more complex models.</p>

                        <p><strong>Step 1: Write the optimization problem</strong></p>
                        <p style="text-align: center;"><code>Œ∏ÃÇ ‚àà arg max<sub>Œ∏</sub> Œ∏‚Åø¬π(1 - Œ∏)‚Åø‚Å∞</code></p>

                        <p><strong>Step 2: Take the log (makes math easier)</strong></p>
                        <p>Instead of maximizing L(Œ∏), we maximize log L(Œ∏). Since log is strictly monotonic (if Œ± > Œ≤ then log Œ± > log Œ≤), the arg max is the same:</p>

                        <p style="text-align: center;"><code>Œ∏ÃÇ ‚àà arg max<sub>Œ∏</sub> log L(Œ∏) = arg max<sub>Œ∏</sub> [n‚ÇÅ log(Œ∏) + n‚ÇÄ log(1 - Œ∏)]</code></p>

                        <p><strong>Why use log-likelihood?</strong></p>
                        <ul>
                            <li><strong>Mathematically easier:</strong> Products become sums, exponents become coefficients</li>
                            <li><strong>Numerically stable:</strong> Prevents underflow with very small probabilities</li>
                            <li><strong>Standard practice:</strong> Almost all ML optimization is done in log space</li>
                        </ul>

                        <p><strong>Step 3: Take the derivative and set it to zero</strong></p>

                        <pre><code class="language-plaintext">d/dŒ∏ [n‚ÇÅ log(Œ∏) + n‚ÇÄ log(1-Œ∏)] = n‚ÇÅ/Œ∏ - n‚ÇÄ/(1-Œ∏)

Setting equal to zero:
n‚ÇÅ/Œ∏ - n‚ÇÄ/(1-Œ∏) = 0
n‚ÇÅ(1-Œ∏) = n‚ÇÄŒ∏
n‚ÇÅ = n‚ÇÄŒ∏ + n‚ÇÅŒ∏
n‚ÇÅ = (n‚ÇÄ + n‚ÇÅ)Œ∏
n‚ÇÅ = nŒ∏

Therefore: Œ∏ = n‚ÇÅ/n</code></pre>

                        <p><strong>Step 4: Verify it's a maximum (not a minimum or saddle point)</strong></p>

                        <p>Check the second derivative:</p>
                        <pre><code class="language-plaintext">d¬≤/dŒ∏¬≤ [n‚ÇÅ log(Œ∏) + n‚ÇÄ log(1-Œ∏)] = -n‚ÇÅ/Œ∏¬≤ - n‚ÇÄ/(1-Œ∏)¬≤ ‚â§ 0</code></pre>

                        <p>Since the second derivative is negative (for n‚ÇÅ, n‚ÇÄ > 0), the function is <strong>concave</strong>, which means our critical point is indeed a <strong>maximum</strong>. ‚úì</p>

                        <h4>Edge Cases: What if n‚ÇÅ = 0 or n‚ÇÄ = 0?</h4>

                        <p>If all data points are 1s (n‚ÇÅ = n, n‚ÇÄ = 0) or all are 0s (n‚ÇÅ = 0, n‚ÇÄ = n), we have a problem:</p>
                        <ul>
                            <li>log(0) = -‚àû makes the derivative approach undefined</li>
                            <li>We'd be dividing by zero in our formula</li>
                        </ul>

                        <p><strong>Solution:</strong> Go back to the plain likelihood Œ∏‚Åø¬π(1-Œ∏)‚Åø‚Å∞ without logs:</p>
                        <ul>
                            <li>If n‚ÇÅ = 0, n‚ÇÄ > 0: Likelihood is (1-Œ∏)‚Åø‚Å∞, maximized at <strong>Œ∏ = 0</strong></li>
                            <li>If n‚ÇÅ > 0, n‚ÇÄ = 0: Likelihood is Œ∏‚Åø¬π, maximized at <strong>Œ∏ = 1</strong></li>
                        </ul>

                        <p>Fortunately, the formula Œ∏ÃÇ = n‚ÇÅ/n still works in these edge cases!</p>

                        <h4>Using the MLE for Inference</h4>

                        <p>Once we've learned Œ∏ÃÇ from data, we can use it for inference tasks:</p>

                        <p><strong>Example:</strong> "If I eat lunch with three randomly selected UBC students, what's the probability any of them are COVID-positive?"</p>

                        <p><strong>Solution:</strong></p>
                        <pre><code class="language-plaintext">Pr(at least 1 positive) = 1 - Pr(all negative)
                         = 1 - (1 - Œ∏)¬≥
                         ‚âà 1 - (1 - Œ∏ÃÇ)¬≥</code></pre>

                        <p>We've gone full circle: <strong>Data ‚Üí Learn Œ∏ÃÇ ‚Üí Use Œ∏ÃÇ for predictions</strong></p>

                        <aside style="background: var(--secondary-bg); padding: 1.5rem; border-left: 4px solid var(--accent-color); margin: 2rem 0;">
                            <h5 style="margin-top: 0;">üéØ The MLE Philosophy</h5>
                            <p>MLE embodies a simple, intuitive principle: <strong>"The parameter should be whatever makes the data we actually observed most likely."</strong></p>
                            <p>If you see 40% heads in 100 coin flips, guess that the coin has a 40% chance of heads. Simple, elegant, and often works remarkably well!</p>
                        </aside>
                    </article>

                    <!-- ===== PROBLEMS WITH MLE ===== -->
                    <article>
                        <h3>Problems with MLE: Overfitting and Unlucky Data</h3>

                        <p>While MLE is elegant and often effective, it has serious limitations‚Äîespecially with small datasets.</p>

                        <h4>Asymptotic Optimality (The Good News)</h4>

                        <p>MLE has excellent <strong>asymptotic properties</strong> as n ‚Üí ‚àû:</p>

                        <blockquote>
                            <p><strong>Consistency:</strong> If data truly comes from X ~ Bern(Œ∏*), then Œ∏ÃÇ<sub>MLE</sub> converges to the true Œ∏* as n ‚Üí ‚àû</p>
                        </blockquote>

                        <p>These kinds of properties are covered in honors/graduate statistics classes. But the key word is <em>asymptotic</em>‚Äîwhat happens when n is <strong>small</strong>?</p>

                        <h4>Problem 1: Sensitivity to Unlucky Data</h4>

                        <p>Consider the dataset <code>X = [1, 0, 1]</code> with Œ∏ÃÇ<sub>MLE</sub> = 2/3 ‚âà 0.67</p>

                        <p><strong>Scenario A:</strong> We see one more data point, x‚ÅΩ‚Å¥‚Åæ = 1</p>
                        <ul>
                            <li>New MLE: Œ∏ÃÇ = 3/4 = 0.75 (increased by 0.08)</li>
                        </ul>

                        <p><strong>Scenario B:</strong> We see one more data point, x‚ÅΩ‚Å¥‚Åæ = 0</p>
                        <ul>
                            <li>New MLE: Œ∏ÃÇ = 2/4 = 0.5 (decreased by 0.17)</li>
                        </ul>

                        <p><strong>The problem:</strong> A single data point causes a huge swing in our estimate! With small n, getting an "unlucky" X can make the MLE very poor.</p>

                        <p>For Bernoullis, this sensitivity decreases quickly with n. But for more complex models, the MLE can severely <strong>overfit</strong>.</p>

                        <h4>Problem 2: Extreme Overfitting on Small Datasets</h4>

                        <p>Now consider a slightly different dataset: <code>X = [1, 1, 1]</code></p>

                        <p><strong>MLE estimate:</strong> Œ∏ÃÇ = 3/3 = 1 (we estimate Pr(X = 1) = 100%)</p>

                        <p><strong>Seems reasonable?</strong> All our observations were 1s, so maybe the probability really is 1...</p>

                        <p><strong>The catastrophe:</strong> Now imagine we see a test dataset with a 0 in it.</p>

                        <pre><code class="language-plaintext">Likelihood of test data = p(0 | Œ∏ÃÇ = 1) = 1 - Œ∏ÃÇ = 1 - 1 = 0</code></pre>

                        <p><mark>Our model assigns ZERO probability to the test data!</mark></p>

                        <p><strong>Why this is terrible:</strong></p>
                        <ul>
                            <li>Zero likelihood means infinite negative log-likelihood</li>
                            <li>Model comparison breaks (can't compare infinities)</li>
                            <li>Gradient-based optimization fails</li>
                            <li>The model has memorized the training data and can't generalize</li>
                        </ul>

                        <p><strong>Real-world analogy:</strong> If a drug works for everyone in a trial of three people, does it <em>always</em> work? Of course not! The sample size is too small to conclude certainty.</p>

                        <h4>Common Solution: Laplace Smoothing</h4>

                        <p>A simple fix (introduced in CPSC 340 for Naive Bayes) is <strong>Laplace smoothing</strong>:</p>

                        <blockquote>
                            <p style="text-align: center; font-size: 1.1em;"><code>Œ∏ÃÇ<sub>Lap</sub> = (n‚ÇÅ + 1)/(n + 2) = (n‚ÇÅ + 1)/((n‚ÇÅ + 1) + (n‚ÇÄ + 1))</code></p>
                        </blockquote>

                        <p><strong>Interpretation:</strong> This is the MLE for a dataset with one extra "imaginary" 0 and one extra "imaginary" 1 added to it!</p>

                        <p><strong>Benefits:</strong></p>
                        <ul>
                            <li>Avoids zero counts (even if n‚ÇÅ = 0, we get Œ∏ÃÇ = 1/2 instead of 0)</li>
                            <li>Reduces sensitivity to small datasets</li>
                            <li>Simple and computationally efficient</li>
                        </ul>

                        <p><strong>Example with X = [1, 1, 1]:</strong></p>
                        <ul>
                            <li>MLE: Œ∏ÃÇ = 3/3 = 1 (dangerous!)</li>
                            <li>Laplace: Œ∏ÃÇ = 4/5 = 0.8 (more reasonable)</li>
                        </ul>

                        <p>Now if we see a 0 in test data, <code>p(0 | Œ∏ÃÇ = 0.8) = 0.2</code>‚Äîsmall but not zero!</p>

                        <h4>Laplace Smoothing is a Special Case of MAP</h4>

                        <p>It turns out that Laplace smoothing is not just an ad-hoc fix‚Äîit's a special case of <strong>Maximum A Posteriori (MAP) estimation</strong> with a specific prior. Let's explore that next!</p>

                        <aside style="background: var(--secondary-bg); padding: 1.5rem; border-left: 4px solid var(--accent-color); margin: 2rem 0;">
                            <h5 style="margin-top: 0;">‚ö†Ô∏è When MLE Fails</h5>
                            <p><strong>Small datasets + complex models = overfitting disaster</strong></p>
                            <p>MLE has no "regularization"‚Äîit will happily fit all the data perfectly, even if that means creating a model that generalizes terribly. The solution? Add prior knowledge through MAP estimation.</p>
                        </aside>
                    </article>

                    <!-- ===== PROBABILITY REVIEW ===== -->
                    <article>
                        <h3>Essential Probability Review: Bayes Rule and Friends</h3>

                        <p>Before we dive into MAP estimation, let's review some fundamental probability concepts. <mark>Make sure you know all of these cold‚Äîthey're essential for the rest of the course!</mark></p>

                        <h4>The Product Rule (Conditional Probability)</h4>

                        <blockquote>
                            <p><strong>Product Rule:</strong> <code>Pr(A ‚à© B) = Pr(A | B) ¬∑ Pr(B)</code></p>
                        </blockquote>

                        <p>This can be rearranged to give the definition of conditional probability:</p>
                        <p style="text-align: center;"><code>Pr(A | B) = Pr(A ‚à© B) / Pr(B)</code></p>

                        <h4>Symmetry of Joints</h4>

                        <p>The order doesn't matter for joint probabilities:</p>
                        <p style="text-align: center;"><code>Pr(A ‚à© B) = Pr(B ‚à© A)</code></p>

                        <h4>Bayes Rule (The Fundamental Tool of Bayesian Inference)</h4>

                        <p>Using the product rule twice and the symmetry of joints:</p>

                        <blockquote>
                            <p><strong>Bayes Rule:</strong></p>
                            <p style="text-align: center; font-size: 1.1em;"><code>Pr(A | B) = [Pr(B | A) ¬∑ Pr(A)] / Pr(B)</code></p>
                        </blockquote>

                        <p><strong>Why it's powerful:</strong> This "flips" the order of conditionals! If we know Pr(B | A) but want Pr(A | B), Bayes rule tells us how to convert between them using the marginal probabilities.</p>

                        <h4>Marginalization Rule</h4>

                        <blockquote>
                            <p><strong>For discrete X:</strong> <code>Pr(A) = Œ£<sub>x</sub> Pr(A ‚à© (X = x))</code></p>
                            <p><strong>For continuous X:</strong> <code>Pr(A) = ‚à´ p(A ‚à© (X = x)) dx</code></p>
                        </blockquote>

                        <p><strong>In words:</strong> To get the probability of A, sum/integrate over all possible values of X.</p>

                        <h4>Combining Bayes and Marginalization</h4>

                        <p>These two rules are "close friends" and combine beautifully:</p>

                        <pre><code class="language-plaintext">p(a) = Œ£<sub>b</sub> p(a, b) = Œ£<sub>b</sub> p(a | b) ¬∑ p(b)

p(a | b) = [p(b | a) ¬∑ p(a)] / p(b) = [p(b | a) ¬∑ p(a)] / [Œ£<sub>a'</sub> p(b | a') ¬∑ p(a')]</code></pre>

                        <p>The denominator uses marginalization to "normalize" the probability!</p>

                        <h4>Conditioning on Everything</h4>

                        <p>These rules still work if you condition everything on some event C:</p>

                        <ul>
                            <li><strong>Product rule:</strong> <code>p(a, b | c) = p(a | b, c) ¬∑ p(b | c)</code></li>
                            <li><strong>Marginalization:</strong> <code>p(a | c) = Œ£<sub>b</sub> p(a, b | c)</code></li>
                        </ul>

                        <aside style="background: var(--secondary-bg); padding: 1.5rem; border-left: 4px solid var(--accent-color); margin: 2rem 0;">
                            <h5 style="margin-top: 0;">üìö If You Need a Refresher</h5>
                            <p>See the probability notes on the course website. These concepts are <strong>absolutely fundamental</strong> to machine learning. If they're not second nature, catch up quickly‚Äîwe'll be using them constantly!</p>
                        </aside>
                    </article>

                    <!-- ===== MAP ESTIMATION ===== -->
                    <article>
                        <h3>Maximum A Posteriori (MAP) Estimation: Incorporating Prior Beliefs</h3>

                        <h4>The Philosophical Shift</h4>

                        <p>MLE asks: <em>"Which Œ∏ makes the data most likely?"</em></p>

                        <blockquote>
                            <p><code>Œ∏ÃÇ<sub>MLE</sub> ‚àà arg max<sub>Œ∏</sub> p(X | Œ∏)</code></p>
                        </blockquote>

                        <p>But this feels backwards! The data could be most likely for a <em>really weird Œ∏</em>, leading to overfitting. What we really want is:</p>

                        <p><strong>"After seeing the data X, which Œ∏ is most likely?"</strong></p>

                        <blockquote>
                            <p><code>Œ∏ÃÇ<sub>MAP</sub> ‚àà arg max<sub>Œ∏</sub> p(Œ∏ | X)</code></p>
                        </blockquote>

                        <p>This is called <strong>Maximum A Posteriori (MAP) estimation</strong>.</p>

                        <h4>From Likelihood to Posterior: Using Bayes Rule</h4>

                        <p>How do we compute p(Œ∏ | X)? Use Bayes rule!</p>

                        <pre><code class="language-plaintext">p(Œ∏ | X) = [p(X | Œ∏) ¬∑ p(Œ∏)] / p(X)
         ‚àù p(X | Œ∏) ¬∑ p(Œ∏)

         Likelihood   Prior</code></pre>

                        <p><strong>Key insight:</strong> p(X) doesn't depend on Œ∏‚Äîit's constant with respect to the arg max!</p>

                        <blockquote>
                            <p><strong>MAP Estimation Formula:</strong></p>
                            <p style="text-align: center; font-size: 1.1em;"><code>p(Œ∏ | X) ‚àù p(X | Œ∏) ¬∑ p(Œ∏)</code></p>
                            <p style="text-align: center;"><code>Posterior ‚àù Likelihood √ó Prior</code></p>
                        </blockquote>

                        <h4>What is a Prior Distribution?</h4>

                        <p><strong>Prior p(Œ∏):</strong> What we believe about Œ∏ <em>before</em> seeing the data</p>

                        <p><strong>Examples of priors:</strong></p>
                        <ul>
                            <li><strong>Coin flipping:</strong> Might want p(Œ∏) higher for values close to Œ∏ = 0.5 (fair coins are more common than biased coins)</li>
                            <li><strong>COVID prevalence:</strong> A separate study estimated Lower Mainland rate at 2%. Could use a prior that prefers Œ∏ not too different from 0.02</li>
                            <li><strong>Machine learning models:</strong> Priors on weights correspond to <em>regularizers</em> (from CPSC 340). Smaller p(Œ∏) for models more likely to overfit</li>
                        </ul>

                        <p><strong>Posterior p(Œ∏ | X):</strong> What we believe about Œ∏ <em>after</em> seeing the data</p>

                        <p>The posterior combines our prior beliefs with evidence from the data!</p>

                        <h4>Example: MAP with a Discrete Prior</h4>

                        <p>Consider <code>X = [1, 1, 0]</code> with MLE Œ∏ÃÇ = 2/3 ‚âà 0.67</p>

                        <p>Let's use a discrete prior that favors a fair coin:</p>

                        <table style="width: 100%; border-collapse: collapse; margin: 1.5rem 0;">
                            <thead>
                                <tr style="background: var(--secondary-bg);">
                                    <th style="padding: 0.75rem; border: 1px solid var(--border-color);">Œ∏</th>
                                    <th style="padding: 0.75rem; border: 1px solid var(--border-color);">Prior Pr(Œ∏)</th>
                                    <th style="padding: 0.75rem; border: 1px solid var(--border-color);">Likelihood p(X|Œ∏)</th>
                                    <th style="padding: 0.75rem; border: 1px solid var(--border-color);">Posterior ‚àù</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">0</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">0.05</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">0 ¬∑ 0 ¬∑ 1 = 0</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">0 ¬∑ 0.05 = 0</td>
                                </tr>
                                <tr>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">0.25</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">0.2</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">0.25 ¬∑ 0.25 ¬∑ 0.75 ‚âà 0.047</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">0.047 ¬∑ 0.2 ‚âà 0.01</td>
                                </tr>
                                <tr style="background: var(--secondary-bg);">
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);"><strong>0.5</strong></td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);"><strong>0.5</strong></td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">0.5 ¬∑ 0.5 ¬∑ 0.5 = 0.125</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);"><strong>0.125 ¬∑ 0.5 ‚âà 0.06</strong></td>
                                </tr>
                                <tr>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">0.75</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">0.2</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">0.75 ¬∑ 0.75 ¬∑ 0.25 ‚âà 0.14</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">0.14 ¬∑ 0.2 ‚âà 0.03</td>
                                </tr>
                                <tr>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">1</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">0.05</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">1 ¬∑ 1 ¬∑ 0 = 0</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">0 ¬∑ 0.05 = 0</td>
                                </tr>
                            </tbody>
                        </table>

                        <p><strong>MAP estimate:</strong> Œ∏ÃÇ<sub>MAP</sub> = 0.5 (compared to MLE of 0.67)</p>

                        <p>The prior "pulled" our estimate toward 0.5 because we gave that value higher prior probability!</p>

                        <p><strong>Note:</strong> p(X) didn't matter‚Äîit's the same constant for all Œ∏, so it cancels out in the arg max.</p>

                        <h4>Understanding the Proportional-To (‚àù) Notation</h4>

                        <blockquote>
                            <p><strong>Definition:</strong> <code>f(Œ∏) ‚àù g(Œ∏)</code> means "there exists some Œ∫ > 0 such that f(Œ∏) = Œ∫ ¬∑ g(Œ∏) for all Œ∏"</p>
                        </blockquote>

                        <p><strong>Examples:</strong></p>
                        <ul>
                            <li><code>10Œ∏¬≤ ‚àù Œ∏¬≤</code> (with Œ∫ = 10)</li>
                            <li><code>‚àöœÄ ¬∑ Œ∏¬≤ ‚àù Œ∏¬≤</code> (with Œ∫ = ‚àöœÄ)</li>
                        </ul>

                        <p><strong>For probability distributions, the constant Œ∫ is unique!</strong></p>

                        <p>Why? Because probabilities must sum/integrate to 1:</p>

                        <pre><code class="language-plaintext">If p(Œ∏) = Œ∫ ¬∑ g(Œ∏) and Œ£<sub>Œ∏</sub> p(Œ∏) = 1, then:
Œ£<sub>Œ∏</sub> Œ∫ ¬∑ g(Œ∏) = 1
Œ∫ ¬∑ Œ£<sub>Œ∏</sub> g(Œ∏) = 1
Œ∫ = 1 / (Œ£<sub>Œ∏</sub> g(Œ∏))

Therefore: p(Œ∏) = g(Œ∏) / (Œ£<sub>Œ∏'</sub> g(Œ∏'))</code></pre>

                        <p><strong>Practical benefit:</strong> We can write <code>p(Œ∏ | X) ‚àù p(X | Œ∏) ¬∑ p(Œ∏)</code> and not worry about the normalization constant until we actually need probabilities (not just arg max)!</p>

                        <p><strong>Example calculation:</strong> From the table above,</p>
                        <pre><code class="language-plaintext">Pr(Œ∏ = 0.5 | X) = 0.06 / (0 + 0.01 + 0.06 + 0.03 + 0) = 0.06/0.10 = 60%</code></pre>
                    </article>

                    <!-- ===== BETA DISTRIBUTION ===== -->
                    <article>
                        <h3>The Beta Distribution: The Perfect Prior for Bernoulli</h3>

                        <h4>From Discrete to Continuous Priors</h4>

                        <p>In the previous example, our prior only allowed Œ∏ ‚àà {0, 0.25, 0.5, 0.75, 1}. But Œ∏ could be <em>any</em> number in [0, 1]!</p>

                        <p>We need a <strong>continuous distribution</strong> over Œ∏ ‚àà [0, 1].</p>

                        <h4>Continuous Distributions and Probability Density Functions</h4>

                        <blockquote>
                            <p><strong>Probability Density Function (pdf):</strong> A function p(Œ∏) with:</p>
                            <ul>
                                <li><code>p(Œ∏) ‚â• 0</code> for all Œ∏</li>
                                <li><code>‚à´<sub>-‚àû</sub><sup>‚àû</sup> p(Œ∏) dŒ∏ = 1</code></li>
                            </ul>
                        </blockquote>

                        <p><strong>Important quirk:</strong> We can have p(Œ∏) > 1 for some Œ∏! (Unlike discrete probabilities)</p>

                        <p><strong>Getting probabilities:</strong> Integrate over a range:</p>
                        <pre><code class="language-plaintext">Pr(0.45 ‚â§ Œ∏ ‚â§ 0.55) = ‚à´<sub>0.45</sub><sup>0.55</sup> p(Œ∏) dŒ∏</code></pre>

                        <p><strong>Single point has zero probability:</strong></p>
                        <pre><code class="language-plaintext">Pr(Œ∏ = 0.5) = ‚à´<sub>0.5</sub><sup>0.5</sup> p(Œ∏) dŒ∏ = 0</code></pre>

                        <p><strong>Proportionality for continuous distributions:</strong></p>
                        <p>If <code>p ‚àù g</code>, then <code>Œ∫ = 1 / ‚à´ g(Œ∏) dŒ∏</code>, so:</p>
                        <p style="text-align: center;"><code>p(Œ∏) = g(Œ∏) / ‚à´ g(Œ∏') dŒ∏'</code></p>

                        <h4>Introducing the Beta Distribution</h4>

                        <p>For Bernoulli models, the most common continuous prior is the <strong>Beta distribution</strong>:</p>

                        <blockquote>
                            <p><strong>Beta Distribution:</strong> For 0 ‚â§ Œ∏ ‚â§ 1, Œ± > 0, Œ≤ > 0:</p>
                            <p style="text-align: center; font-size: 1.1em;"><code>p(Œ∏ | Œ±, Œ≤) ‚àù Œ∏<sup>Œ±-1</sup> (1 - Œ∏)<sup>Œ≤-1</sup></code></p>
                        </blockquote>

                        <p><strong>Key properties:</strong></p>
                        <ul>
                            <li>Density is 0 if Œ∏ ‚àâ [0, 1] (only defined on the valid range)</li>
                            <li>Looks like a Bernoulli likelihood with (Œ±-1) ones and (Œ≤-1) zeros</li>
                            <li><strong>But:</strong> The <em>argument</em> is Œ∏, not Œ± or Œ≤!</li>
                            <li>This is a "probability distribution over probabilities"</li>
                        </ul>

                        <p><strong>Full formula (with normalization):</strong></p>
                        <p style="text-align: center;"><code>p(Œ∏ | Œ±, Œ≤) = Œ∏<sup>Œ±-1</sup> (1 - Œ∏)<sup>Œ≤-1</sup> / B(Œ±, Œ≤)</code></p>

                        <p>where <code>B(Œ±, Œ≤) = ‚à´<sub>0</sub><sup>1</sup> Œ∏<sup>Œ±-1</sup> (1 - Œ∏)<sup>Œ≤-1</sup> dŒ∏</code> is the <strong>Beta function</strong> (the normalization constant).</p>

                        <h4>Why is Beta So Popular?</h4>

                        <p><strong>Reason 1: Flexibility</strong></p>

                        <p>The Beta distribution can take many shapes depending on Œ± and Œ≤:</p>
                        <ul>
                            <li><strong>Œ± = Œ≤ = 1:</strong> Uniform distribution (all Œ∏ equally likely)</li>
                            <li><strong>Œ± = Œ≤ = 2:</strong> Mild preference towards Œ∏ = 0.5</li>
                            <li><strong>Œ± = Œ≤ > 2:</strong> Strong preference towards Œ∏ = 0.5</li>
                            <li><strong>Œ± = Œ≤ < 1:</strong> Prefers extreme values (near 0 or 1)</li>
                            <li><strong>Œ± > Œ≤:</strong> Prefers larger Œ∏ (closer to 1)</li>
                            <li><strong>Œ± < Œ≤:</strong> Prefers smaller Œ∏ (closer to 0)</li>
                        </ul>

                        <p>See the <a href="https://en.wikipedia.org/wiki/File:Beta_distribution_pdf.svg" target="_blank">Wikipedia animation</a> showing Beta distributions for different Œ±, Œ≤ values.</p>

                        <p><strong>Limitations:</strong></p>
                        <ul>
                            <li>Can't bias towards "0.25 or 0.75" (bimodal preferences)</li>
                            <li>Can't say "half the time it'll be exactly 0.5" (discrete mass)</li>
                        </ul>

                        <p>But it's "flexible enough" for most use cases!</p>

                        <p><strong>Reason 2: Conjugacy (The Real Magic)</strong></p>

                        <p>The <em>main</em> reason Beta is so popular: the posterior and MAP have <strong>really simple closed-form solutions</strong>. Let's see why!</p>

                        <h4>The Beta-Bernoulli Model: Conjugate Prior Magic</h4>

                        <p>Suppose we use a Beta prior with Bernoulli likelihood:</p>

                        <pre><code class="language-plaintext">Prior:      Œ∏ ~ Beta(Œ±, Œ≤)
Likelihood: X | Œ∏ ~ Bern(Œ∏)

Posterior:
p(Œ∏ | X, Œ±, Œ≤) ‚àù p(X | Œ∏) ¬∑ p(Œ∏ | Œ±, Œ≤)
             ‚àù [Œ∏<sup>n‚ÇÅ</sup> (1-Œ∏)<sup>n‚ÇÄ</sup>] ¬∑ [Œ∏<sup>Œ±-1</sup> (1-Œ∏)<sup>Œ≤-1</sup>]
             = Œ∏<sup>n‚ÇÅ+Œ±-1</sup> (1-Œ∏)<sup>n‚ÇÄ+Œ≤-1</sup>
             = Œ∏<sup>(n‚ÇÅ+Œ±)-1</sup> (1-Œ∏)<sup>(n‚ÇÄ+Œ≤)-1</sup></code></pre>

                        <p><mark>This is another Beta distribution!</mark></p>

                        <blockquote>
                            <p><strong>Beta-Bernoulli Posterior:</strong></p>
                            <p style="text-align: center; font-size: 1.1em;"><code>Œ∏ | X, Œ±, Œ≤ ~ Beta(Œ± + n‚ÇÅ, Œ≤ + n‚ÇÄ)</code></p>
                        </blockquote>

                        <p><strong>Why does it have to be Beta?</strong> Because the proportionality constant Œ∫ is unique for probability distributions! If <code>p(Œ∏) ‚àù Œ∏<sup>Œ±ÃÉ-1</sup>(1-Œ∏)<sup>Œ≤ÃÉ-1</sup></code>, then by definition <code>Œ∏ ~ Beta(Œ±ÃÉ, Œ≤ÃÉ)</code>.</p>

                        <p><strong>This property is called conjugacy:</strong> The prior and posterior are in the same family of distributions.</p>

                        <aside style="background: var(--secondary-bg); padding: 1.5rem; border-left: 4px solid var(--accent-color); margin: 2rem 0;">
                            <h5 style="margin-top: 0;">üéØ Conjugacy Intuition</h5>
                            <p><strong>Prior:</strong> "I believe Œ∏ looks like I've seen (Œ±-1) ones and (Œ≤-1) zeros"</p>
                            <p><strong>Data:</strong> "I actually observed n‚ÇÅ ones and n‚ÇÄ zeros"</p>
                            <p><strong>Posterior:</strong> "Now I believe Œ∏ looks like I've seen (Œ±-1 + n‚ÇÅ) ones and (Œ≤-1 + n‚ÇÄ) zeros"</p>
                            <p>The prior acts like "pseudocounts" that you add to your actual counts!</p>
                        </aside>

                        <h4>MAP Estimation with Beta Prior</h4>

                        <p>The posterior is <code>Œ∏ | X ~ Beta(Œ±ÃÉ, Œ≤ÃÉ)</code> where Œ±ÃÉ = n‚ÇÅ + Œ±, Œ≤ÃÉ = n‚ÇÄ + Œ≤.</p>

                        <p>The full pdf is:</p>
                        <p style="text-align: center;"><code>p(Œ∏ | X, Œ±, Œ≤) = Œ∏<sup>Œ±ÃÉ-1</sup> (1-Œ∏)<sup>Œ≤ÃÉ-1</sup> / B(Œ±ÃÉ, Œ≤ÃÉ)</code></p>

                        <p>Taking the log and setting the derivative to zero:</p>

                        <pre><code class="language-plaintext">log p(Œ∏ | X) = (Œ±ÃÉ-1) log(Œ∏) + (Œ≤ÃÉ-1) log(1-Œ∏) - log B(Œ±ÃÉ, Œ≤ÃÉ)

d/dŒ∏ log p(Œ∏ | X) = (Œ±ÃÉ-1)/Œ∏ - (Œ≤ÃÉ-1)/(1-Œ∏) = 0

(Œ±ÃÉ-1)(1-Œ∏) = (Œ≤ÃÉ-1)Œ∏
Œ±ÃÉ - 1 - Œ±ÃÉŒ∏ + Œ∏ = Œ≤ÃÉŒ∏ - Œ∏
Œ±ÃÉ - 1 = (Œ±ÃÉ + Œ≤ÃÉ - 2)Œ∏

Œ∏ = (Œ±ÃÉ - 1) / (Œ±ÃÉ + Œ≤ÃÉ - 2)</code></pre>

                        <blockquote>
                            <p><strong>MAP Estimate with Beta Prior:</strong></p>
                            <p style="text-align: center; font-size: 1.1em;"><code>Œ∏ÃÇ<sub>MAP</sub> = (n‚ÇÅ + Œ± - 1) / (n + Œ± + Œ≤ - 2)</code></p>
                        </blockquote>

                        <p>(assuming Œ±ÃÉ > 1 and Œ≤ÃÉ > 1; edge cases possible otherwise)</p>

                        <h4>Special Cases: Recovering MLE and Laplace Smoothing</h4>

                        <table style="width: 100%; border-collapse: collapse; margin: 1.5rem 0;">
                            <thead>
                                <tr style="background: var(--secondary-bg);">
                                    <th style="padding: 0.75rem; text-align: left; border: 1px solid var(--border-color);">Prior (Œ±, Œ≤)</th>
                                    <th style="padding: 0.75rem; text-align: left; border: 1px solid var(--border-color);">MAP Estimate</th>
                                    <th style="padding: 0.75rem; text-align: left; border: 1px solid var(--border-color);">Interpretation</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">Œ± = 1, Œ≤ = 1</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">n‚ÇÅ/n</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);"><strong>Uniform prior ‚Üí MLE</strong></td>
                                </tr>
                                <tr>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">Œ± = 2, Œ≤ = 2</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">(n‚ÇÅ+1)/(n+2)</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);"><strong>Laplace smoothing</strong></td>
                                </tr>
                                <tr>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">Œ± = Œ≤ > 2</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">Closer to 0.5</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">Stronger bias towards fair coin</td>
                                </tr>
                                <tr>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">Œ± = Œ≤ < 1</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">Away from 0.5</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">Bias towards extreme values</td>
                                </tr>
                                <tr>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">Œ± > Œ≤</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">Towards 1</td>
                                    <td style="padding: 0.75rem; border: 1px solid var(--border-color);">Bias towards more 1s</td>
                                </tr>
                            </tbody>
                        </table>

                        <p><strong>As n ‚Üí ‚àû:</strong> The prior stops mattering and MAP ‚Üí MLE</p>

                        <p>The data overwhelms the prior! But with relatively small n, the prior significantly affects our estimate.</p>
                    </article>

                    <!-- ===== HYPERPARAMETERS ===== -->
                    <article>
                        <h3>Hyperparameters and Cross-Validation</h3>

                        <h4>What Are Hyperparameters?</h4>

                        <blockquote>
                            <p><strong>Hyperparameters:</strong> The parameters of the prior (Œ± and Œ≤ in our case), which "affect the complexity of the model"</p>
                        </blockquote>

                        <p><strong>Examples from CPSC 340:</strong></p>
                        <ul>
                            <li>Degree of a polynomial</li>
                            <li>Depth of a decision tree</li>
                            <li>Neural network architecture</li>
                            <li>Regularization weight (Œª in ridge regression)</li>
                            <li>Number of rounds of gradient boosting</li>
                            <li>Gradient descent step size</li>
                        </ul>

                        <p>In general: <em>anything hard to fit with your learning algorithm</em> becomes a hyperparameter.</p>

                        <h4>Why Not Just Fit Hyperparameters from Data?</h4>

                        <p>You might think: "Why not just maximize training likelihood over Œ± and Œ≤?"</p>

                        <p><strong>Problem:</strong> This would just recover MLE!</p>

                        <pre><code class="language-plaintext">Œ∏ÃÇ<sub>MAP</sub> = (n‚ÇÅ + Œ± - 1) / (n + Œ± + Œ≤ - 2)

As Œ±, Œ≤ ‚Üí 1: Œ∏ÃÇ<sub>MAP</sub> ‚Üí n‚ÇÅ/n = Œ∏ÃÇ<sub>MLE</sub></code></pre>

                        <p>Maximizing training likelihood would drive Œ±, Œ≤ ‚Üí 1, eliminating the regularization benefit of the prior!</p>

                        <h4>The Solution: Validation Sets and Cross-Validation</h4>

                        <p>The standard approach from CPSC 340:</p>

                        <ol>
                            <li><strong>Split data:</strong> Divide X into "training" and "validation" sets</li>
                            <li><strong>Grid search:</strong> For different values of hyperparameters (Œ±, Œ≤):
                                <ul>
                                    <li>Find the MAP estimate on the training set</li>
                                    <li>Evaluate its likelihood on the validation set</li>
                                </ul>
                            </li>
                            <li><strong>Select best:</strong> Pick the hyperparameters with highest validation likelihood</li>
                        </ol>

                        <p><strong>Why this works:</strong> Validation likelihood approximates performance on totally new, unseen data (generalization error).</p>

                        <h4>Common Pitfalls</h4>

                        <p>‚ö†Ô∏è <strong>Overfitting to the validation set</strong> happens all the time!</p>

                        <ul>
                            <li>If you try too many hyperparameter combinations, you'll eventually find one that just got "lucky" on validation</li>
                            <li>This shows up in UBC PhD theses, top-tier conferences, and production ML systems</li>
                            <li>Solutions: Nested cross-validation, held-out test sets, Bayesian optimization</li>
                        </ul>

                        <p><strong>For more depth:</strong> CPSC 532D covers this more rigorously from a Bayesian perspective!</p>

                        <aside style="background: var(--secondary-bg); padding: 1.5rem; border-left: 4px solid var(--accent-color); margin: 2rem 0;">
                            <h5 style="margin-top: 0;">üí° The Hyperparameter Hierarchy</h5>
                            <p><strong>Data ‚Üí Parameters (via learning) ‚Üí Predictions</strong></p>
                            <p><strong>Validation data ‚Üí Hyperparameters (via validation) ‚Üí Parameters ‚Üí Predictions</strong></p>
                            <p>There's a "meta-level" where we're learning how to learn!</p>
                        </aside>
                    </article>

                </div>
            </section>

            <section class="topics">
                <h2>Topics Covered</h2>
                <ul id="topics-list">
                    <li>Understanding the likelihood function L(Œ∏) = p(X|Œ∏) and why it's not a probability distribution</li>
                    <li>Maximum Likelihood Estimation (MLE): Œ∏ÃÇ = n‚ÇÅ/n for Bernoulli distributions</li>
                    <li>Deriving MLE using calculus: log-likelihood maximization and verifying concavity</li>
                    <li>Problems with MLE: sensitivity to small datasets and overfitting (zero probability catastrophe)</li>
                    <li>Probability review: Bayes rule, marginalization, product rule, and proportional-to notation</li>
                    <li>Maximum A Posteriori (MAP) estimation: maximizing p(Œ∏|X) instead of p(X|Œ∏)</li>
                    <li>The Beta distribution as a conjugate prior for Bernoulli likelihood</li>
                    <li>Beta-Bernoulli posterior: Œ∏|X ~ Beta(Œ±+n‚ÇÅ, Œ≤+n‚ÇÄ) and MAP formula</li>
                    <li>Special cases: uniform prior (Œ±=Œ≤=1) recovers MLE, Œ±=Œ≤=2 gives Laplace smoothing</li>
                    <li>Hyperparameter selection via cross-validation and avoiding validation set overfitting</li>
                </ul>
            </section>

            <section class="assignments">
                <h2>Assignments & Action Items</h2>
                <ul id="assignments-list">
                    <li><strong>Sign up for Piazza</strong> from cs.ubc.ca/~dsuth/440 for announcements and recordings</li>
                    <li><strong>Assignment 1 coming out tonight/tomorrow</strong> - start it even if you're on the waitlist</li>
                    <li><strong>CBTF quiz booking</strong> will be available soon - watch Piazza for instructions</li>
                    <li>Practice deriving MLE for Bernoulli by hand: take log, set derivative to zero, verify concavity</li>
                    <li>Work through the discrete prior MAP example with different prior values</li>
                    <li>Understand why Laplace smoothing = Beta(2,2) prior</li>
                    <li>Verify the Beta-Bernoulli posterior derivation: multiply likelihood √ó prior and identify the Beta form</li>
                    <li>Review Bayes rule, product rule, and marginalization - these are fundamental!</li>
                    <li>Explore Beta distribution shapes at different (Œ±,Œ≤) values using the Wikipedia animation</li>
                    <li>Think about: when does the prior matter more vs. when does data overwhelm the prior?</li>
                </ul>
            </section>
        </div>

        <footer class="lecture-footer">
            <a href="../../index.html#cpsc440" class="back-link">‚Üê Back to CPSC_440</a>
        </footer>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
</body>
</html>
